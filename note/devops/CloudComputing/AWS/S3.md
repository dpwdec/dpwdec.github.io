---
layout: page
exclude: true
title: S3
---

S3 stands for **simple storage service**. It is one of AWS's longest serving products and is defined by Amazon as a "secure, durable, highly-scalable object storage" system.

S3 is used for storing **flat files** e.g. text, video, images - files that do not change periodically and have already been encoded. This is not suitable for database storage.

S3 is an **object based storage system**:

- It is used for storing files and content and allows you to upload files.
- Files can be between 0 bytes and 5 terabytes in size.
- Storage is unlimited

This is in contrast to a **block based storage system** which is used for installing an operating systems etc.

## Features

- Tiered storage
- Lifecycle Management
- Versioning
- Encryption
- Secure data using **Access Control Lists** and **Bucket Policies**.

## Buckets

S3 files are **stored in buckets** which are like folders in the cloud. 

When creating a new bucket, the **bucket name must be unique globally** across the entire AWS S3 storage system. Buckets are available at URL in the format `https://s3-eu-west-1.amazonaws.com/<bucket name>` which adds a unique DNS entry to amazon for access to the bucket. This is why the bucket namespace has to be globally unique.

When you **successfully upload a file** to S3 you will receive a status code `200` which allows you to test if an upload was successful or not.

## Objects

S3 is a **key value based object store**.

An Object in S3 **consists of**:

- `Key`: The name of the object e.g. `menu.txt` or `funnycat.gif`
- `Value`: The data that makes up the object (as a sequence of bytes)
- `Version ID`
- `Metadata`

They also contain **subresources** consisting of:

- `Access Control Lists`
- `Torrent`

## Data Consistency

There is **read after write consistency** for `PUT` on new objects. This means, as soon as you create a new object you will be able to read that data immediately.

There is **eventual consistency** for overwrite `PUT` and `DELETE` on existing objects. This means it can take some time for updates and deletes to propagate across the S3 system. After updating you may still be able to read the old version of a file and after deletion you may still be able to access a file for a period of time.

## Reliability

S3 platform is **built for 99.99% availability**, however **Amazon only guarantee 99.9% availability**.

Amazon guarantee **11 x 9 durability of files** which is equivalent to **99.999999999%**. Durability describes you certain you can be that a file will not be lost once it is uploaded to S3, thus S3 is very reliable in this capacity.

## Security

### Access Control Lists

An **access control list** allows you to **create access rules on an individual file basis**. For example, only allowing certain users to access a file.

### Bucket Policies

**Bucket Policies** allow you to **create access rules for entire buckets** to a control the security of large sets of data.

## Storage Classes

Amazon offers several storage class options using S3. You find a breakdown of the options [here](https://aws.amazon.com/s3/storage-classes/).

### S3 Standard

The original S3 storage service.

- 99.99% Availability and 99x11% durability
- Stored redundantly across multiple devices
- Can survive loss of two facilities concurrently

### S3 IA

S3 - IA stands for **infrequently accessed** data which is data that you might only access every 2 -3 months.

- Designed for data that is not used often
- Allows for rapid access when needed (within milliseconds)
- Lower fee than S3 **but charges incurred for retrieval** of data.

### S3 One Zone IA

S3 One Zone IA is **similar to IA but limits data to a single availability zone**.

### S3 Intelligent Tiering

S3 Intelligent Tiering uses machine learning to automatically **optimise storage usage for the lowest cost based on how you use the stored files**. It will use some combination of the above options for thee optimisation to this end.

### S3 Glacier

- Used for storing files that are used very infrequently
- Costing is competitive with on-premises storage solutions
- **Retrieval times are configurable** for between minutes and hours for retrieval

### S3 Glacier Deep Archive

- Amazon's **lowest cost storage solution**.
- **Retrieval time takes 12 hours + from when file is requested.**

## Charges

Charging for S3 is based on:

- Storage usage
- Requests made
- Storage Management usage
- Data transfer usage
- Transfer Acceleration usage
- Cross Region Replication usage

## Transfer Acceleration

**Transfer Acceleration** is used for **speeding up and securing long distance file transfers between users and an S3 bucket**. This is **achieved by using Amazon's CloudFront edge locations** which are a network of globally distributed centers that extend Amazon's internal network.

For example, if a user in AUstralia is trying to upload a file to an S3 bucket in London. Transfer Acceleration will allow them to upload the file directly to a CloudFront edge location in Australia (or whatever is nearest to them) this will then send that file directly across the world to the London S3 storage via Amazon's internal network (no longer over the public internet) which supports an optimised network that runs incredibly f










<!--stackedit_data:
eyJoaXN0b3J5IjpbLTgyODc0MDk4MSwtODc4MTgwNjEsNjQ3Nz
YxMzgsMjA4OTM4MzIwLC05NDA0ODYyMTYsMTY4MDAxNDk5Niwt
MjEyMjY0NTQwNCwtMTkxMTk4MzA3XX0=
-->